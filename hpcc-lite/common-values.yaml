global:
  # Settings in the global section apply to all HPCC components in all subcharts

  image:
    ## It is recommended to name a specific version rather than latest, for any non-trivial deployment
    ## For best results, the helm chart version and platform version should match, which is the default if version is
    ## not specified. Do not override without good reason as undefined behavior may result. 
    ## version: x.y.z
    root: "hpccsystems"    # change this if you want to pull your images from somewhere other than DockerHub hpccsystems
    pullPolicy: IfNotPresent
    ## If you need to provide credentials to pull your image, they should be added as a k8s secret, and the secret name provided here
    # imagePullSecrets: xxx

  # logging sets the default logging information for all components. Can be overridden locally
  logging:
    detail: 80
  
  egress:
    ## If restricted is set, NetworkPolicies will include egress restrictions to allow connections from pods only to the minimum required by the system
    ## Set to false to disable all egress policy restrictions (not recommended)
    restricted: true

  ## visibilities section can be used to set labels, annotations and service type for any service with the specified visibility
  visibilities:
    cluster:
      type: ClusterIP
    local:
      annotations:
        # This annotation will make azure load balancer use an internal rather than an internet-visible address
        # May want different values on different cloud providers or use-cases. For example on AWS you may want to use
        #service.beta.kubernetes.io/aws-load-balancer-internal: "true"
        service.beta.kubernetes.io/azure-load-balancer-internal: "true"
      type: LoadBalancer
      # If ingress is specified, an ingress Network Policy will be created for any pod implementing a service with this visibility
      # Default allows ingress from anywhere, but more restrictive rules can be used if preferred.
      # Ingress rules can also be overridden by individual services
      ingress:
      - {}
    global:
      #labels:
      #  mylabel: "4"
      type: LoadBalancer
      ingress:
      - {}
      ## CIDRS allowed to access this service.
      #loadBalancerSourceRanges: [1.2.3.4/32, 5.6.7.8/32]

secrets:
  storage: {}

  authn: {}

  ecl: {}

  eclUser: {}

  codeSign: {}

  codeVerify: {}

  system: {}

  git: {}

dali:
- name: mydali
  auth: none
  services: # internal house keeping services
    coalescer:
      service:
        servicePort: 8877
      #interval: 2 # (hours)
      #at: "* * * * *" # cron type schedule, i.e. Min(0-59) Hour(0-23) DayOfMonth(1-31) Month(1-12) DayOfWeek(0-6)
      #minDeltaSize: 50 # (Kb) will not start coalescing until delta log is above this threshold
      #resources:
      #  cpu: "1"
      #  memory: "1G"

  #resources:
  #  cpu: "1"
  #  memory: "4G"

esp:
- name: eclwatch
  ## Pre-configured esp applications include eclwatch, eclservices, and eclqueries
  application: eclwatch
  auth: none
  replicas: 1
  ## The following 'corsAllowed' section is used to configure CORS support
  ##   origin - the origin to support CORS requests from
  ##   headers - the headers to allow for the given origin via CORS
  ##   methods - the HTTP methods to allow for the given origin via CORS
  ##
  #corsAllowed:
  ## origin starting with https will only allow https CORS
  #- origin: https://*.my.com
  #  headers:
  #  - "X-X"
  #  methods:
  #  - "GET"
  #  - "OPTIONS"
  ## origin starting with http will allow http or https CORS
  #- origin: http://www.example.com
  #  headers:
  #  - "*"
  #  methods:
  #  - "GET"
  #  - "POST"
  #  - "OPTIONS"

# Add remote clients to generated client certificates and make the ESP require that one of the generated certificates is provided by a client in order to connect
#   When setting up remote clients make sure that certificates.issuers.remote.enabled is set to true.
# remoteClients:
# - name: petfoodApplicationProd
#   organization: petfoodDept
#   secretTemplate:
#     annotations:
#       kubed.appscode.com/sync: "hpccenv=petfoodAppProd" # use kubed config-syncer to replicate certificate to namespace with matching annotation (also supports syncing with separate aks clusters)

  service:
    ## port can be used to change the local port used by the pod. If omitted, the default port (8880) is used
    port: 8888
    ## servicePort controls the port that this service will be exposed on, either internally to the cluster, or externally
    servicePort: 8010
    ## wsdlAddress should be set to the host and port which clients can use to hit this service.
    #   This address is added to the service wsdl files which simplify setting up a SOAP client to hit this service.  There may be many external factors determining the address
    #   that is accible to clients.
    # wsdlAddress: clientfacingaddress:8010
    ## Specify visibility: local (or global) if you want the service available from outside the cluster. Typically, eclwatch and wsecl are published externally, while eclservices is designed for internal use.
    visibility: global
    ## Annotations can be specified on a service - for example to specify provider-specific information such as service.beta.kubernetes.io/azure-load-balancer-internal-subnet
    #annotations:
    #  service.beta.kubernetes.io/azure-load-balancer-internal-subnet: "mysubnet"
    #  The service.annotations prefixed with hpcc.eclwatch.io should not be declared here. They can be declared
    #  in other services in order to be exposed in the ECLWatch interface. Similar function can be used by other 
    #  applications. For other applications, the "eclwatch" inside the service.annotations should be replaced by
    #  their application names. 
    #  hpcc.eclwatch.io/enabled: "true"
    #  hpcc.eclwatch.io/description: "some description"
    ## You can also specify labels on a service
    #labels:
    #  mylabel: "3"
    ## Links specify the web links for a service. The web links may be shown on ECLWatch.
    #links:
    #- name: linkname
    #  description: "some description"
    #  url: "http://abc.com/def?g=1"
    ## CIDRS allowed to access this service.
    #loadBalancerSourceRanges: [1.2.3.4/32, 5.6.7.8/32]
  # Increase maxRequestEntityLength when query deployments (or similar actions) start to fail because they surpass the maximum size
  #  default for EclWatch is 60M, default for other services is 8M
  #maxRequestEntityLength: 70M
  #resources:
  #  cpu: "1"
  #  memory: "2G"
- name: eclservices
  application: eclservices
  auth: none
  replicas: 1
  service:
    servicePort: 8010
    visibility: cluster
  # Increase maxRequestEntityLength when query deployments (or similar actions) start to fail because they surpass the maximum size
  #  default for EclWatch is 60M, default for other services is 8M
  #maxRequestEntityLength: 9M
  #resources:
  #  cpu: "250m"
  #  memory: "1G"

# For simple cases, you can uncomment the last two lines to disable sasha
# sasha: 
# disabled: true